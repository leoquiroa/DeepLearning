{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import PIL\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the CNN\n",
    "* Two ways of initializing the neural network, either as a sequence of layers or as a graph. \n",
    "* CNN is a sequence of layers\n",
    "* Conv2D for images and Conv3D for videos (add time)\n",
    "* Add the fully connected layers into a classic ANN\n",
    "* The problem is non-linear so we need to have non-linearity in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "# 32 = number of filters, start with 2^5=32, then 2^6=64, until 2^7=128\n",
    "# (3,3) = (rows,columns)\n",
    "# (64,64,3) = size of our input image\n",
    "# relu = to avoid (-) values in the feature maps and have non-linearity in the CNN\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "# pool_size = windows size of the feature map\n",
    "# use less intensive computational power \n",
    "# recommendation size (2,2)\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "# 1 CL train 85% and test 75% a difference of 10%\n",
    "# improve the accuracy of 7% in the test dataset and reduce the diff in train/test\n",
    "# a common practice is to double the number of feature detectors 32, 64, 128, ...\n",
    "# 1 CL train 85% and test 82% a difference of 3%\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "# A huge vector where each node represent an input pixel image \n",
    "# Independent from all the pixels around it, only contains information from itself\n",
    "# With a convolutional step we can codify spatial structure around the pixel\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "# Classic ANN composed of fully connected layers\n",
    "# Convert the input image into one dimensional vector that contains information of the spatial structure\n",
    "# Use the output (flatten huge vector) as an input of a ANN\n",
    "# too-small to make the classifier a good model \n",
    "# too-big to make the classifier too highly compute-intensive\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "# output layer\n",
    "# sigmoid - to return probabilities of a binary outcome\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "# Stochastic gradient descent algorithm = adam\n",
    "# Binary Cross Entropy corresponds to the logarithmic loss used in classification problem\n",
    "# Since the output is binary, thus, a binary cross entropy loss function is needed\n",
    "# Performance metric = accuracy\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the CNN to the images\n",
    "* Good performance on train dataset and poor performance on test dataset -> overfit\n",
    "* Overfitting is also caused for few data train\n",
    "* Can capture the patterns but fail at generalization\n",
    "* More real data or data augmentation to produce synthetic data\n",
    "* Rotate, flip, shift\n",
    "* Shear mapping is a linear map that displaces each point in fixed direction, by an amount proportional to its signed distance from the line that is parallel to that direction and goes through the origin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* rescale the images to be between 0 and 1\n",
    "* shear_range for some random transvections\n",
    "* zoom changes\n",
    "* horizontal flip\n",
    "* batch_size: some random samples of our images will be included\n",
    "* batch_size, contains the number of images that will go through the CNN after the weight will be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('./dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('./dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to improve accuracy?\n",
    "* Add another convolutional layer\n",
    "* Add another fully connected layer\n",
    "* Increase accuracy and decrease loss\n",
    "* Increase the size of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "8000/8000 [==============================] - 1104s 138ms/step - loss: 0.3891 - accuracy: 0.8153 - val_loss: 0.2711 - val_accuracy: 0.8091\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 986s 123ms/step - loss: 0.1594 - accuracy: 0.9362 - val_loss: 1.0453 - val_accuracy: 0.7991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1bae8640da0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 2,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "print(training_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = image.load_img('./dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = image.load_img('./dataset/single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "classifier.predict(test_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
